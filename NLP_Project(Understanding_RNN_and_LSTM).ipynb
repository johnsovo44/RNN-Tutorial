{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP Project(Understanding RNN and LSTM)",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/johnsovo44/RNN-Tutorial/blob/master/NLP_Project(Understanding_RNN_and_LSTM).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M-YkEtE_AB_",
        "colab_type": "code",
        "outputId": "33b6f517-4088-464c-b3a3-f1869b8eea34",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        }
      },
      "source": [
        "!pip install tensorflow"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: tensorflow in /usr/local/lib/python3.6/dist-packages (1.14.0)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.15.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied: tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.14.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.16.5)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.33.6)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.12.0)\n",
            "Requirement already satisfied: keras-applications>=1.0.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.0.8)\n",
            "Requirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.1.7)\n",
            "Requirement already satisfied: tensorboard<1.15.0,>=1.14.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.14.0)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.8.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (0.3.2)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (1.11.2)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow) (3.7.1)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.6->tensorflow) (2.8.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (3.1.1)\n",
            "Requirement already satisfied: setuptools>=41.0.0 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (41.2.0)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tensorboard<1.15.0,>=1.14.0->tensorflow) (0.16.0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5YGIcehm_GFS",
        "colab_type": "code",
        "outputId": "fad40fee-9632-475e-be5d-cdb2b18e7139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "import tensorflow as tf\n",
        "print(tf.__version__)\n"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "1.14.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "79_8FlmO_N0X",
        "colab_type": "text"
      },
      "source": [
        "# Purpose\n",
        "\n",
        "I'lll be following along with Jason Brownlee's article on how LTSM is implemented. To differentiate my work from his, he has laid out some extension ideas at the end help with experimentation. I will also use a different unstructured dataset once I have gotten an understanding of his work. \n",
        "\n",
        "Link to the article: https://machinelearningmastery.com/text-generation-lstm-recurrent-neural-networks-python-keras/\n",
        "\n",
        "By the end of this lesson I will know the following:\n",
        "\n",
        "- Where to download a free corpus of text to further train text generative models: [Project Gutenberg](https://www.gutenberg.org/) (experiments are just limited to text either. You can generate source code, LaTex, HTML or Markdown and more)\n",
        "- How to frame the problem of text sequences to a recurrent neural network generative model.\n",
        "- How to develop an LSTM to generate plausible text sequences for a given problem. \n",
        "\n",
        "For additional understanding of RNN models please watch this video: [Afr iendly Introduction to Recurrent Neural Networks](https://www.youtube.com/watch?v=UNmqTiOnRfg)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mZmieu4A1MAp",
        "colab_type": "text"
      },
      "source": [
        "# Approach\n",
        "\n",
        "\n",
        "\n",
        "1.   Write out code\n",
        "2. Troubleshoot\n",
        "2.   Comment out code and what is happening at each step\n",
        "3. Experiment with extension ideas\n",
        "4. Insert in own dataset\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GLflahBiyPpe",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers import Dropout\n",
        "from keras.layers import LSTM\n",
        "from keras.utils import np_utils\n",
        "from keras.callbacks import ModelCheckpoint"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_4NZZJd20hc3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 148
        },
        "outputId": "ac9b7d0e-d68e-4208-f73a-1e6839c093ce"
      },
      "source": [
        "filename = \"C:\\Users\\Vonn\\Downloads\\wonderland.txt\"\n",
        "raw_text = open(filename, 'r', encoding = 'utf-8').read()\n",
        "raw_text = raw_text.lower()"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-8-20f0331f0fae>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    filename = \"C:\\Users\\Vonn\\Downloads\\wonderland.txt\"\u001b[0m\n\u001b[0m              ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m (unicode error) 'unicodeescape' codec can't decode bytes in position 2-3: truncated \\UXXXXXXXX escape\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v5-kArAf5fQ1",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "raw_text = \"\"\"Project Gutenberg's Alice's Adventures in Wonderland, by Lewis Carroll\n",
        "\n",
        "This eBook is for the use of anyone anywhere at no cost and with\n",
        "almost no restrictions whatsoever.  You may copy it, give it away or\n",
        "re-use it under the terms of the Project Gutenberg License included\n",
        "with this eBook or online at www.gutenberg.org\n",
        "\n",
        "\n",
        "Title: Alice's Adventures in Wonderland\n",
        "\n",
        "Author: Lewis Carroll\n",
        "\n",
        "Posting Date: June 25, 2008 [EBook #11]\n",
        "Release Date: March, 1994\n",
        "[Last updated: December 20, 2011]\n",
        "\n",
        "Language: English\n",
        "\n",
        "\n",
        "*** START OF THIS PROJECT GUTENBERG EBOOK ALICE'S ADVENTURES IN WONDERLAND ***\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "ALICE'S ADVENTURES IN WONDERLAND\n",
        "\n",
        "Lewis Carroll\n",
        "\n",
        "THE MILLENNIUM FULCRUM EDITION 3.0\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "CHAPTER I. Down the Rabbit-Hole\n",
        "\n",
        "Alice was beginning to get very tired of sitting by her sister on the\n",
        "bank, and of having nothing to do: once or twice she had peeped into the\n",
        "book her sister was reading, but it had no pictures or conversations in\n",
        "it, 'and what is the use of a book,' thought Alice 'without pictures or\n",
        "conversations?'\n",
        "\n",
        "So she was considering in her own mind (as well as she could, for the\n",
        "hot day made her feel very sleepy and stupid), whether the pleasure\n",
        "of making a daisy-chain would be worth the trouble of getting up and\n",
        "picking the daisies, when suddenly a White Rabbit with pink eyes ran\n",
        "close by her.\n",
        "\n",
        "There was nothing so VERY remarkable in that; nor did Alice think it so\n",
        "VERY much out of the way to hear the Rabbit say to itself, 'Oh dear!\n",
        "Oh dear! I shall be late!' (when she thought it over afterwards, it\n",
        "occurred to her that she ought to have wondered at this, but at the time\n",
        "it all seemed quite natural); but when the Rabbit actually TOOK A WATCH\n",
        "OUT OF ITS WAISTCOAT-POCKET, and looked at it, and then hurried on,\n",
        "Alice started to her feet, for it flashed across her mind that she had\n",
        "never before seen a rabbit with either a waistcoat-pocket, or a watch\n",
        "to take out of it, and burning with curiosity, she ran across the field\n",
        "after it, and fortunately was just in time to see it pop down a large\n",
        "rabbit-hole under the hedge.\n",
        "\n",
        "In another moment down went Alice after it, never once considering how\n",
        "in the world she was to get out again.\n",
        "\n",
        "The rabbit-hole went straight on like a tunnel for some way, and then\n",
        "dipped suddenly down, so suddenly that Alice had not a moment to think\n",
        "about stopping herself before she found herself falling down a very deep\n",
        "well.\n",
        "\n",
        "Either the well was very deep, or she fell very slowly, for she had\n",
        "plenty of time as she went down to look about her and to wonder what was\n",
        "going to happen next. First, she tried to look down and make out what\n",
        "she was coming to, but it was too dark to see anything; then she\n",
        "looked at the sides of the well, and noticed that they were filled with\n",
        "cupboards and book-shelves; here and there she saw maps and pictures\n",
        "hung upon pegs. She took down a jar from one of the shelves as\n",
        "she passed; it was labelled 'ORANGE MARMALADE', but to her great\n",
        "disappointment it was empty: she did not like to drop the jar for fear\n",
        "of killing somebody, so managed to put it into one of the cupboards as\n",
        "she fell past it.\"\"\"\n",
        "\n",
        "raw_text = raw_text.lower()\n",
        "\n",
        "# this is here because the file will not open right now. Need to troubleshoot\n",
        "# in second phase. But this is here so I can see what needs troubleshooting. "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8RrLPwoP1IG9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "chars = sorted(list(set(raw_text)))\n",
        "char_to_int = dict((c,i) for i, c in enumerate(chars))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KnDWbJPr5_0d",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 840
        },
        "outputId": "74ec66c8-c311-4174-f920-92a733f8e2af"
      },
      "source": [
        "char_to_int"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{'\\n': 0,\n",
              " ' ': 1,\n",
              " '!': 2,\n",
              " '#': 3,\n",
              " \"'\": 4,\n",
              " '(': 5,\n",
              " ')': 6,\n",
              " '*': 7,\n",
              " ',': 8,\n",
              " '-': 9,\n",
              " '.': 10,\n",
              " '0': 11,\n",
              " '1': 12,\n",
              " '2': 13,\n",
              " '3': 14,\n",
              " '4': 15,\n",
              " '5': 16,\n",
              " '8': 17,\n",
              " '9': 18,\n",
              " ':': 19,\n",
              " ';': 20,\n",
              " '?': 21,\n",
              " '[': 22,\n",
              " ']': 23,\n",
              " 'a': 24,\n",
              " 'b': 25,\n",
              " 'c': 26,\n",
              " 'd': 27,\n",
              " 'e': 28,\n",
              " 'f': 29,\n",
              " 'g': 30,\n",
              " 'h': 31,\n",
              " 'i': 32,\n",
              " 'j': 33,\n",
              " 'k': 34,\n",
              " 'l': 35,\n",
              " 'm': 36,\n",
              " 'n': 37,\n",
              " 'o': 38,\n",
              " 'p': 39,\n",
              " 'q': 40,\n",
              " 'r': 41,\n",
              " 's': 42,\n",
              " 't': 43,\n",
              " 'u': 44,\n",
              " 'v': 45,\n",
              " 'w': 46,\n",
              " 'x': 47,\n",
              " 'y': 48}"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-7cufhWx4eJ9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "fe75ffcb-288a-4365-e780-8d7be4d07a1d"
      },
      "source": [
        "n_chars = len(raw_text)\n",
        "n_vocab = len(chars)\n",
        "print(\"Total Characters: \", n_chars)\n",
        "print(\"total Vocab: \", n_vocab)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Characters:  3084\n",
            "total Vocab:  49\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pkHMTtPL50AR",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JL4HiVmV6RwT",
        "colab_type": "text"
      },
      "source": [
        "So N distinct vocab characters are able to produce N characters for the full text. There are obviously characters in here that could be removed in future cleaning but first let's see how they will play a role in the model. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_uBhWjr86aBh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q2gvInwG6z0o",
        "colab_type": "text"
      },
      "source": [
        "# Defining the Training Data\n",
        "\n",
        "(possible area to revisit given flexibility in choosing how to break up the text and exposing it to the network during training. In the tutorial wea re going to split the text in traunches of 100 characters. In the future you could try just the words or sentences.)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Gc9iMeKO9KsY",
        "colab_type": "text"
      },
      "source": [
        "A Note on training: \"The way it works is each training pattern of the network is comprised of 100 time steps of one character (X) followed by one character output(y).\" A window is sliding arcoss 100 characters and then guessing the next output (this goes for every character after the first 100 characters). 100 characters is not standard.\n",
        "\n",
        "An example of this is the word chapter (from the tutorial):\n",
        "\n",
        "If we had a 5 character window instead...\n",
        "\n",
        "X = chapt\n",
        "\n",
        "y = e\n",
        "\n",
        "next one...\n",
        "\n",
        "X = hapte\n",
        "\n",
        "y = r\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Hd2b0g_V-FI4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7415f8c3-f679-4a09-fb9a-aa0e6773156e"
      },
      "source": [
        "seq_length = 100\n",
        "dataX = []\n",
        "dataY = []\n",
        "for i in range(0, n_chars - seq_length, 1):\n",
        "  seq_in = raw_text[i:i + seq_length]\n",
        "  seq_out = raw_text[i + seq_length]\n",
        "  dataX.append([char_to_int[char] for char in seq_in])\n",
        "  dataY.append(char_to_int[seq_out])\n",
        "n_patterns = len(dataX)\n",
        "print(\"Total Patterns: \", n_patterns)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total Patterns:  2984\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RRJq1QbgAF1I",
        "colab_type": "text"
      },
      "source": [
        "The tutorial ended up having the 100 less patterns as they did characters. So if you do this again, make sure that holds true for the full text."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eCvAxMTqAf9o",
        "colab_type": "text"
      },
      "source": [
        "# Prepare for Keras"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LLbtkp2rB_EJ",
        "colab_type": "text"
      },
      "source": [
        "The LSTM network needs the array in the form of [samples, timesteps, features]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1b0FQvu0CGCa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X = np.reshape(dataX, (n_patterns, seq_length, 1))\n",
        "X = X/float(n_vocab)\n",
        "y = np_utils.to_categorical(dataY)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MASacYjrCqDN",
        "colab_type": "text"
      },
      "source": [
        "## Defining LSTM"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "myGgEU8GDuzT",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "4970180b-e712-400e-b5ad-9cf79c5957ba"
      },
      "source": [
        "model= Sequential()\n",
        "model.add(LSTM(256, input_shape = (X.shape[1], X.shape[2])))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(y.shape[1], activation = 'softmax'))\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam')\n",
        "\n",
        "# I would like to go back and understand the basis for using each line of code."
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:66: The name tf.get_default_graph is deprecated. Please use tf.compat.v1.get_default_graph instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:541: The name tf.placeholder is deprecated. Please use tf.compat.v1.placeholder instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:4432: The name tf.random_uniform is deprecated. Please use tf.random.uniform instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:148: The name tf.placeholder_with_default is deprecated. Please use tf.compat.v1.placeholder_with_default instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3733: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/optimizers.py:793: The name tf.train.Optimizer is deprecated. Please use tf.compat.v1.train.Optimizer instead.\n",
            "\n",
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/keras/backend/tensorflow_backend.py:3576: The name tf.log is deprecated. Please use tf.math.log instead.\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GcJHW9cgEbcz",
        "colab_type": "text"
      },
      "source": [
        "## Defining a checkpoint"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aLlQnSj2Ef81",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "filepath = \"weights-improvement-{epoch:02d}-{loss:.4f}.hdf5\"\n",
        "checkpoint = ModelCheckpoint(filepath, \n",
        "                             monitor='loss',\n",
        "                             verbose=1, \n",
        "                             save_best_only=True,\n",
        "                             mode='min')\n",
        "callbacks_list = [checkpoint]"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "S4jjG5qYFdG0",
        "colab_type": "text"
      },
      "source": [
        "Getting an error here. We haven't imported ModelCheckpoint yet so I don't know where we would get that. Need to understand later."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FarJToy6F-o9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "4e5cc16d-2a65-4f49-d88d-9f662639928b"
      },
      "source": [
        "model.fit(X,\n",
        "          y,\n",
        "          epochs = 20,\n",
        "          batch_size = 128,\n",
        "          callbacks = callbacks_list)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "WARNING:tensorflow:From /usr/local/lib/python3.6/dist-packages/tensorflow/python/ops/math_grad.py:1250: add_dispatch_support.<locals>.wrapper (from tensorflow.python.ops.array_ops) is deprecated and will be removed in a future version.\n",
            "Instructions for updating:\n",
            "Use tf.where in 2.0, which has the same broadcast rule as np.where\n",
            "Epoch 1/20\n",
            "2984/2984 [==============================] - 20s 7ms/step - loss: 3.3763\n",
            "\n",
            "Epoch 00001: loss improved from inf to 3.37626, saving model to weights-improvement-01-3.3763.hdf5\n",
            "Epoch 2/20\n",
            "2984/2984 [==============================] - 19s 6ms/step - loss: 3.0873\n",
            "\n",
            "Epoch 00002: loss improved from 3.37626 to 3.08734, saving model to weights-improvement-02-3.0873.hdf5\n",
            "Epoch 3/20\n",
            "2984/2984 [==============================] - 19s 6ms/step - loss: 3.0767\n",
            "\n",
            "Epoch 00003: loss improved from 3.08734 to 3.07675, saving model to weights-improvement-03-3.0767.hdf5\n",
            "Epoch 4/20\n",
            "2984/2984 [==============================] - 19s 6ms/step - loss: 3.0618\n",
            "\n",
            "Epoch 00004: loss improved from 3.07675 to 3.06175, saving model to weights-improvement-04-3.0618.hdf5\n",
            "Epoch 5/20\n",
            "2984/2984 [==============================] - 19s 6ms/step - loss: 3.0679\n",
            "\n",
            "Epoch 00005: loss did not improve from 3.06175\n",
            "Epoch 6/20\n",
            "2984/2984 [==============================] - 19s 6ms/step - loss: 3.0563\n",
            "\n",
            "Epoch 00006: loss improved from 3.06175 to 3.05629, saving model to weights-improvement-06-3.0563.hdf5\n",
            "Epoch 7/20\n",
            "2984/2984 [==============================] - 19s 6ms/step - loss: 3.0529\n",
            "\n",
            "Epoch 00007: loss improved from 3.05629 to 3.05294, saving model to weights-improvement-07-3.0529.hdf5\n",
            "Epoch 8/20\n",
            "2984/2984 [==============================] - 19s 6ms/step - loss: 3.0558\n",
            "\n",
            "Epoch 00008: loss did not improve from 3.05294\n",
            "Epoch 9/20\n",
            "2984/2984 [==============================] - 19s 6ms/step - loss: 3.0468\n",
            "\n",
            "Epoch 00009: loss improved from 3.05294 to 3.04683, saving model to weights-improvement-09-3.0468.hdf5\n",
            "Epoch 10/20\n",
            "2984/2984 [==============================] - 19s 6ms/step - loss: 3.0502\n",
            "\n",
            "Epoch 00010: loss did not improve from 3.04683\n",
            "Epoch 11/20\n",
            "2984/2984 [==============================] - 19s 6ms/step - loss: 3.0432\n",
            "\n",
            "Epoch 00011: loss improved from 3.04683 to 3.04318, saving model to weights-improvement-11-3.0432.hdf5\n",
            "Epoch 12/20\n",
            "2984/2984 [==============================] - 19s 6ms/step - loss: 3.0434\n",
            "\n",
            "Epoch 00012: loss did not improve from 3.04318\n",
            "Epoch 13/20\n",
            "2984/2984 [==============================] - 19s 6ms/step - loss: 3.0367\n",
            "\n",
            "Epoch 00013: loss improved from 3.04318 to 3.03670, saving model to weights-improvement-13-3.0367.hdf5\n",
            "Epoch 14/20\n",
            "2984/2984 [==============================] - 19s 6ms/step - loss: 3.0331\n",
            "\n",
            "Epoch 00014: loss improved from 3.03670 to 3.03306, saving model to weights-improvement-14-3.0331.hdf5\n",
            "Epoch 15/20\n",
            "2984/2984 [==============================] - 19s 6ms/step - loss: 3.0280\n",
            "\n",
            "Epoch 00015: loss improved from 3.03306 to 3.02804, saving model to weights-improvement-15-3.0280.hdf5\n",
            "Epoch 16/20\n",
            "2984/2984 [==============================] - 19s 6ms/step - loss: 3.0214\n",
            "\n",
            "Epoch 00016: loss improved from 3.02804 to 3.02140, saving model to weights-improvement-16-3.0214.hdf5\n",
            "Epoch 17/20\n",
            "2984/2984 [==============================] - 19s 6ms/step - loss: 3.0125\n",
            "\n",
            "Epoch 00017: loss improved from 3.02140 to 3.01254, saving model to weights-improvement-17-3.0125.hdf5\n",
            "Epoch 18/20\n",
            "2984/2984 [==============================] - 19s 6ms/step - loss: 2.9975\n",
            "\n",
            "Epoch 00018: loss improved from 3.01254 to 2.99753, saving model to weights-improvement-18-2.9975.hdf5\n",
            "Epoch 19/20\n",
            "2984/2984 [==============================] - 19s 6ms/step - loss: 2.9839\n",
            "\n",
            "Epoch 00019: loss improved from 2.99753 to 2.98393, saving model to weights-improvement-19-2.9839.hdf5\n",
            "Epoch 20/20\n",
            "2984/2984 [==============================] - 19s 6ms/step - loss: 2.9723\n",
            "\n",
            "Epoch 00020: loss improved from 2.98393 to 2.97235, saving model to weights-improvement-20-2.9723.hdf5\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7f84c613c940>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dpGCpadsJGtm",
        "colab_type": "text"
      },
      "source": [
        "# Generating Text with an LSTM Network"
      ]
    }
  ]
}